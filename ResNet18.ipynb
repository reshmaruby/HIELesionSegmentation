{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install SimpleITK\n",
        "# !pip install matplotlib\n",
        "# !pip install scikit-learn\n",
        "# !pip install segmentation_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ9xfbzfdJzH"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import os\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWFwXQbedCz6"
      },
      "outputs": [],
      "source": [
        "adc_folder_path = 'BONBID2023_Train/1ADC_ss'\n",
        "adc_files = [os.path.join(adc_folder_path, f) for f in os.listdir(adc_folder_path) if f.endswith('.mha')]\n",
        "adc_files = sorted(adc_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFuCh6dPdqmk"
      },
      "outputs": [],
      "source": [
        "zadc_folder_path = 'BONBID2023_Train/2Z_ADC'\n",
        "zadc_files = [os.path.join(zadc_folder_path, f) for f in os.listdir(zadc_folder_path) if f.endswith('.mha')]\n",
        "zadc_files = sorted(zadc_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqdn183NdqVI"
      },
      "outputs": [],
      "source": [
        "label_folder_path = 'BONBID2023_Train/3LABEL'\n",
        "label_files = [os.path.join(label_folder_path, f) for f in os.listdir(label_folder_path) if f.endswith('.mha')]\n",
        "label_files = sorted(label_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbzsHOvTEdQL"
      },
      "source": [
        "# **Read and display data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRoh97tFENTx"
      },
      "source": [
        "Read and display ADC data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3H5ryBIdRAD"
      },
      "outputs": [],
      "source": [
        "adc_data = []\n",
        "adc_stik_data = []\n",
        "for file in adc_files:\n",
        "    image = sitk.ReadImage(file)\n",
        "    adc_stik_data.append(image)\n",
        "    array = sitk.GetArrayFromImage(image)\n",
        "    adc_data.append(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "GQVKc3Zb-GQ3",
        "outputId": "2fa2cfa6-e1a7-430c-bb54-fa057132320e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5,5, figsize=(14,14))\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    if i < adc_data[0].shape[0]:\n",
        "        ax.imshow(adc_data[0][i], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJFEu09CEUcF"
      },
      "source": [
        "Read and display Zadc data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk4oBqa1d371"
      },
      "outputs": [],
      "source": [
        "zadc_data = []\n",
        "for file in zadc_files:\n",
        "    image = sitk.ReadImage(file)\n",
        "    array = sitk.GetArrayFromImage(image)\n",
        "    zadc_data.append(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "e7T6sFfaEDeV",
        "outputId": "cb1d836f-5cec-4a1e-8200-edf2cde8476e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5,5, figsize=(14, 14))\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    if i < zadc_data[0].shape[0]:\n",
        "        ax.imshow(zadc_data[0][i], cmap=\"jet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI5MimNpEZdB"
      },
      "source": [
        "Read and display label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r_5gDr1d4kK"
      },
      "outputs": [],
      "source": [
        "label_data = []\n",
        "for file in label_files:\n",
        "    image = sitk.ReadImage(file)\n",
        "    array = sitk.GetArrayFromImage(image)\n",
        "    label_data.append(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "Zm-7PMPW8jwN",
        "outputId": "a9aae118-27e1-4457-fa95-4a058423b165"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5,5, figsize=(14, 14))\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    if i < label_data[0].shape[0]:\n",
        "        ax.imshow(label_data[0][i], cmap=\"copper\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLPjLaY3SETL"
      },
      "source": [
        "# **Ready data for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBE2zNirScMT"
      },
      "outputs": [],
      "source": [
        "# Flatten a list of data with n length and (m, 128, 128) shape of each array, so it becomes a list of n*m of arrays of shape (128, 128)\n",
        "\n",
        "flattened_adc_data = [item for sublist in adc_data for item in sublist]\n",
        "flattened_zadc_data = [item for sublist in zadc_data for item in sublist]\n",
        "flattened_label_data = [item for sublist in label_data for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "flattened_zadc_data_train, flattened_zadc_data_test, flattened_label_data_train, flattened_label_data_test = train_test_split(flattened_zadc_data, flattened_label_data, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def slice_image(image):\n",
        "    \"\"\"\n",
        "    Slices the given image into 64x64 patches.\n",
        "    \n",
        "    Args:\n",
        "    image (numpy.ndarray): The image to be sliced, expected shape is (H, W).\n",
        "    \n",
        "    Returns:\n",
        "    list: A list of 64x64 image patches.\n",
        "    \"\"\"\n",
        "    patches = []\n",
        "    h, w = image.shape\n",
        "    \n",
        "    if (h, w) == (256, 256):\n",
        "        # Slicing 256x256 image into sixteen non-overlapping 64x64 patches\n",
        "        for i in range(0, h, 64):\n",
        "            for j in range(0, w, 64):\n",
        "                patches.append(image[i:i+64, j:j+64])\n",
        "    elif (h, w) == (160, 160):\n",
        "        # Slicing 160x160 image with overlap to create 64x64 patches\n",
        "        for i in range(0, h-64+1, 64):\n",
        "            for j in range(0, w-64+1, 64):\n",
        "                patches.append(image[i:i+64, j:j+64])\n",
        "        # Adding overlapping patches\n",
        "        patches.append(image[96:160, 96:160])\n",
        "    elif (h, w) == (128, 128):\n",
        "        # Slicing 128x128 image with overlap to create 64x64 patches\n",
        "        for i in range(0, h-64+1, 64):\n",
        "            for j in range(0, w-64+1, 64):\n",
        "                patches.append(image[i:i+64, j:j+64])\n",
        "    elif (h, w) == (64, 64):\n",
        "        # Returning the image itself if it's already 64x64\n",
        "        patches.append(image)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported image size. Expected (64, 64), (128, 128), (160, 160), or (256, 256).\")\n",
        "    \n",
        "    return patches\n",
        "\n",
        "def process_images_and_labels(images, labels):\n",
        "    \"\"\"\n",
        "    Processes lists of images and labels, slicing each into 64x64 patches.\n",
        "    \n",
        "    Args:\n",
        "    images (list): List of numpy.ndarray images.\n",
        "    labels (list): List of numpy.ndarray labels corresponding to the images.\n",
        "    \n",
        "    Returns:\n",
        "    tuple: Two lists containing the sliced images and corresponding labels.\n",
        "    \"\"\"\n",
        "    all_image_patches = []\n",
        "    all_label_patches = []\n",
        "    \n",
        "    for image, label in zip(images, labels):\n",
        "        image_patches = slice_image(image)\n",
        "        label_patches = slice_image(label)\n",
        "        \n",
        "        all_image_patches.extend(image_patches)\n",
        "        all_label_patches.extend(label_patches)\n",
        "    \n",
        "    return all_image_patches, all_label_patches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flattened_cropped_zadc_data_list, flattened_cropped_label_data_list = process_images_and_labels(flattened_zadc_data_train, flattened_label_data_train)\n",
        "\n",
        "flattened_test_cropped_zadc_data_list, flattened_test_cropped_label_data_list = process_images_and_labels(flattened_zadc_data_test, flattened_label_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_patches(original_image, patches):\n",
        "    \"\"\"\n",
        "    Display the 64x64 patches in a grid to verify their placement.\n",
        "    \n",
        "    Args:\n",
        "    original_image (numpy.ndarray): The original image before slicing.\n",
        "    patches (list): A list of 64x64 image patches.\n",
        "    \"\"\"\n",
        "    h, w = original_image.shape\n",
        "    fig, axs = plt.subplots(h // 64, w // 64, figsize=(10, 10))\n",
        "    \n",
        "    patch_index = 0\n",
        "    for i in range(h // 64):\n",
        "        for j in range(w // 64):\n",
        "            axs[i, j].imshow(patches[patch_index])\n",
        "            axs[i, j].axis('off')\n",
        "            patch_index += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display patches for the first image\n",
        "original_image = flattened_zadc_data_train[875]\n",
        "patches = slice_image(original_image)\n",
        "display_patches(original_image, patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stitch_image(patches, original_shape):\n",
        "    \"\"\"\n",
        "    Stitches 64x64 patches back together into the original image.\n",
        "    \n",
        "    Args:\n",
        "    patches (list): A list of 64x64 image patches.\n",
        "    original_shape (tuple): The shape of the original image (height, width).\n",
        "    \n",
        "    Returns:\n",
        "    numpy.ndarray: The reconstructed image.\n",
        "    \"\"\"\n",
        "    h, w = original_shape\n",
        "    reconstructed_image = np.zeros(original_shape)\n",
        "    \n",
        "    patch_index = 0\n",
        "    for i in range(0, h, 64):\n",
        "        for j in range(0, w, 64):\n",
        "            reconstructed_image[i:i+64, j:j+64] = patches[patch_index]\n",
        "            patch_index += 1\n",
        "    \n",
        "    return reconstructed_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display patches for the first image\n",
        "original_image = flattened_zadc_data_test[3]\n",
        "patches = slice_image(original_image)\n",
        "display_patches(original_image, patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rRlNdM0QPm2",
        "outputId": "70681863-0a77-4f91-bf92-b231bda92028"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "# Convert the list of arrays to a single NumPy array\n",
        "flattened_cropped_zadc_data = np.array(flattened_cropped_zadc_data_list)\n",
        "\n",
        "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
        "flattened_cropped_zadc_data = flattened_cropped_zadc_data.reshape((len(flattened_cropped_zadc_data_list), 64, 64, 1))\n",
        "\n",
        "# Print the shape to verify\n",
        "print(flattened_cropped_zadc_data.shape)\n",
        "\n",
        "flattened_cropped_label_data = np.array(flattened_cropped_label_data_list)\n",
        "flattened_cropped_label_data = flattened_cropped_label_data.reshape((len(flattened_cropped_label_data_list), 64, 64, 1))\n",
        "\n",
        "# Print the shape to verify\n",
        "print(flattened_cropped_label_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Test Data\n",
        "# Convert the list of arrays to a single NumPy array\n",
        "flattened_test_cropped_zadc_data = np.array(flattened_test_cropped_zadc_data_list)\n",
        "\n",
        "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
        "flattened_test_cropped_zadc_data = flattened_test_cropped_zadc_data.reshape((len(flattened_test_cropped_zadc_data_list), 64, 64, 1))\n",
        "\n",
        "# Print the shape to verify\n",
        "print(flattened_test_cropped_zadc_data.shape)\n",
        "\n",
        "flattened_test_cropped_label_data = np.array(flattened_test_cropped_label_data_list)\n",
        "flattened_test_cropped_label_data = flattened_test_cropped_label_data.reshape((len(flattened_test_cropped_label_data_list), 64, 64, 1))\n",
        "\n",
        "# Print the shape to verify\n",
        "print(flattened_test_cropped_label_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SbMGfWZQhy7"
      },
      "source": [
        "# **U Net: ResNet18**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm\n",
        "# Segmentation Models: using `keras` framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model1: Dice Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "checkpoint_dir = '/Epochs/ResNet18dice'\n",
        "checkpoint_filepath = os.path.join(checkpoint_dir, 'model_checkpoint_{epoch:02d}.keras')\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "latest_checkpoint = max([os.path.join(checkpoint_dir, f) for f in os.listdir(checkpoint_dir) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
        "log_filepath = 'training_log_ResNet18dice.csv'\n",
        "\n",
        "# Create the CSVLogger\n",
        "csv_logger = CSVLogger(log_filepath, append=True)\n",
        "\n",
        "# ModelCheckpoint callback to save the model\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_mean_io_u',\n",
        "    mode='max',\n",
        "    save_best_only=False,\n",
        "    save_freq='epoch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import segmentation_models as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BACKBONE = 'resnet18'\n",
        "\n",
        "# load your data\n",
        "x_train1, x_val1, y_train1, y_val1 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# define model\n",
        "model1 = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(64, 64, 1))\n",
        "model1.compile(\n",
        "    'Adam',\n",
        "    loss=sm.losses.DiceLoss,\n",
        "    metrics=[sm.metrics.iou_score, sm.metrics.FScore],\n",
        ")\n",
        "\n",
        "history1 = model1.fit(\n",
        "   x=x_train1,\n",
        "   y=y_train1,\n",
        "   batch_size=32,\n",
        "   epochs=500,\n",
        "   validation_data=(x_val1, y_val1),\n",
        "   callbacks=[model_checkpoint_callback, csv_logger]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy, loss, and MeanIoU values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.plot(history1.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Dice Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history1.history['iou_score'])\n",
        "plt.plot(history1.history['val_iou_score'])\n",
        "plt.title('Model MeanIoU')\n",
        "plt.ylabel('MeanIoU')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history1.history['f1-score'])\n",
        "plt.plot(history1.history['val_f1-score'])\n",
        "plt.title('Model F1 Score')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Add a main title to the entire figure\n",
        "plt.suptitle('Model 1 : ResNet18 Dice Loss', fontsize=16)\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('resnetDice.png', dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TEST\n",
        "IMAGE_NUMBER = 230\n",
        "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
        "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
        "patches = slice_image(original_image)\n",
        "\n",
        "patches_data = np.array(patches)\n",
        "\n",
        "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
        "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
        "\n",
        "predictions = model1.predict(patches_data)\n",
        "predictions = predictions.reshape((len(predictions), 64, 64))\n",
        "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image)\n",
        "plt.title('ZADC image')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(label_image, cmap=\"grey\")\n",
        "plt.title('Label image')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
        "plt.title('Predicted image')\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('resNetDicePrediction.png', dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.compile(\n",
        "    'Adam',\n",
        "    loss=dice_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model1.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation results on test data (Dice):\")\n",
        "print(f\"Dice Loss: {evaluation[0]}\")\n",
        "print(f\"IOU Score: {evaluation[1]}\")\n",
        "print(f\"F1 Score: {evaluation[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.compile(\n",
        "    'Adam',\n",
        "    loss=focal_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model1.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation results on test data (Dice):\")\n",
        "print(f\"Focal Loss: {evaluation[0]}\")\n",
        "print(f\"IOU Score: {evaluation[1]}\")\n",
        "print(f\"F1 Score: {evaluation[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model 2: Dice + Focal Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Define paths\n",
        "checkpoint_dir2 = '/Epochs/ResNet18dicefocal'\n",
        "checkpoint_filepath2 = os.path.join(checkpoint_dir2, 'model_checkpoint_{epoch:02d}.keras')\n",
        "if not os.path.exists(checkpoint_dir2):\n",
        "    os.makedirs(checkpoint_dir2)\n",
        "latest_checkpoint2 = max([os.path.join(checkpoint_dir2, f) for f in os.listdir(checkpoint_dir2) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
        "log_filepath2 = 'training_log_ResNet18dicefocal.csv'\n",
        "        \n",
        "# Create the CSVLogger\n",
        "csv_logger2 = CSVLogger(log_filepath2, append=True)\n",
        "\n",
        "# ModelCheckpoint callback to save the model\n",
        "model_checkpoint_callback2 = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath2,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_mean_io_u',\n",
        "    mode='max',\n",
        "    save_best_only=False,\n",
        "    save_freq='epoch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import segmentation_models as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BACKBONE = 'resnet18'\n",
        "\n",
        "# load your data\n",
        "x_train2, x_val2, y_train2, y_val2 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# define model\n",
        "model2 = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(64, 64, 1))\n",
        "\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
        "\n",
        "model2.compile(\n",
        "    'Adam',\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "history2 = model2.fit(\n",
        "   x=x_train2,\n",
        "   y=y_train2,\n",
        "   batch_size=32,\n",
        "   epochs=500,\n",
        "   validation_data=(x_val2, y_val2),\n",
        "   callbacks=[model_checkpoint_callback2, csv_logger2]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy, loss, and MeanIoU values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Dice Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history2.history['iou_score'])\n",
        "plt.plot(history2.history['val_iou_score'])\n",
        "plt.title('Model MeanIoU')\n",
        "plt.ylabel('MeanIoU')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history2.history['f1-score'])\n",
        "plt.plot(history2.history['val_f1-score'])\n",
        "plt.title('Model F1 Score')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Add a main title to the entire figure\n",
        "plt.suptitle('Model 2 : ResNet18 Dice + Focal Loss', fontsize=16)\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('resnetDiceFocal.png', dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TEST\n",
        "IMAGE_NUMBER = 230\n",
        "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
        "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
        "patches = slice_image(original_image)\n",
        "\n",
        "patches_data = np.array(patches)\n",
        "\n",
        "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
        "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
        "\n",
        "predictions = model2.predict(patches_data)\n",
        "predictions = predictions.reshape((len(predictions), 64, 64))\n",
        "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image)\n",
        "plt.title('ZADC image')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(label_image, cmap=\"grey\")\n",
        "plt.title('Label image')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
        "plt.title('Predicted image')\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('resnetDiceFocalPrediction.png', dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(\n",
        "    'Adam',\n",
        "    loss=dice_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model2.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation results on test data (Dice+Focal):\")\n",
        "print(f\"Dice Loss: {evaluation[0]}\")\n",
        "print(f\"IOU Score: {evaluation[1]}\")\n",
        "print(f\"F1 Score: {evaluation[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(\n",
        "    'Adam',\n",
        "    loss=focal_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model2.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation results on test data (Dice+Focal):\")\n",
        "print(f\"Focal Loss: {evaluation[0]}\")\n",
        "print(f\"IOU Score: {evaluation[1]}\")\n",
        "print(f\"F1 Score: {evaluation[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model 3: 0.75 Dice + 0.25 Focal Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Define paths\n",
        "checkpoint_dir3 = '/Epochs/ResNet1875dice25focal'\n",
        "checkpoint_filepath3 = os.path.join(checkpoint_dir3, 'model_checkpoint_{epoch:02d}.keras')\n",
        "if not os.path.exists(checkpoint_dir3):\n",
        "    os.makedirs(checkpoint_dir3)\n",
        "latest_checkpoint3 = max([os.path.join(checkpoint_dir3, f) for f in os.listdir(checkpoint_dir3) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
        "log_filepath3 = 'training_log_ResNet1875dice25focal.csv'\n",
        "\n",
        "# Create the CSVLogger\n",
        "csv_logger3 = CSVLogger(log_filepath3, append=True)\n",
        "\n",
        "# ModelCheckpoint callback to save the model\n",
        "model_checkpoint_callback3 = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath3,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_mean_io_u',\n",
        "    mode='max',\n",
        "    save_best_only=False,\n",
        "    save_freq='epoch'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import segmentation_models as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "BACKBONE = 'resnet18'\n",
        "\n",
        "# load your data\n",
        "x_train3, x_val3, y_train3, y_val3 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# define model\n",
        "model3 = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(64, 64, 1))\n",
        "\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "total_loss = (0.75 * dice_loss) + (0.25 * focal_loss)\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
        "\n",
        "model3.compile(\n",
        "    'Adam',\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "history3 = model3.fit(\n",
        "   x=x_train3,\n",
        "   y=y_train3,\n",
        "   batch_size=32,\n",
        "   epochs=1,\n",
        "   validation_data=(x_val3, y_val3),\n",
        "#    callbacks=[model_checkpoint_callback3, csv_logger3]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy, loss, and MeanIoU values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history3.history['loss'])\n",
        "plt.plot(history3.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Dice Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history3.history['iou_score'])\n",
        "plt.plot(history3.history['val_iou_score'])\n",
        "plt.title('Model MeanIoU')\n",
        "plt.ylabel('MeanIoU')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history3.history['f1-score'])\n",
        "plt.plot(history3.history['val_f1-score'])\n",
        "plt.title('Model F1 Score')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Add a main title to the entire figure\n",
        "plt.suptitle('Model 3 : ResNet18 0.75 Dice + 0.25 Focal Loss', fontsize=16)\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('resnet75Dice25Focal.png', dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TEST\n",
        "IMAGE_NUMBER = 230\n",
        "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
        "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
        "patches = slice_image(original_image)\n",
        "\n",
        "patches_data = np.array(patches)\n",
        "\n",
        "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
        "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
        "\n",
        "predictions = model3.predict(patches_data)\n",
        "predictions = predictions.reshape((len(predictions), 64, 64))\n",
        "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image)\n",
        "plt.title('ZADC image')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(label_image, cmap=\"grey\")\n",
        "plt.title('Label image')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
        "plt.title('Predicted image')\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig('resnet75Dice25FocalPrediction.png', dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss()\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3.compile(\n",
        "    'Adam',\n",
        "    loss=dice_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model3.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation results on test data (0.75 Dice + 0.25 Focal):\")\n",
        "print(f\"Dice Loss: {evaluation[0]}\")\n",
        "print(f\"IOU Score: {evaluation[1]}\")\n",
        "print(f\"F1 Score: {evaluation[2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3.compile(\n",
        "    'Adam',\n",
        "    loss=focal_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model3.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
        "\n",
        "# Print the results\n",
        "print(\"Evaluation results on test data (0.75 Dice + 0.25 Focal):\")\n",
        "print(f\"Focal Loss: {evaluation[0]}\")\n",
        "print(f\"IOU Score: {evaluation[1]}\")\n",
        "print(f\"F1 Score: {evaluation[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **UI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7862\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict_mri(image):\n",
        "    \"\"\"\n",
        "    Takes an MRI scan image, processes it using the pre-trained model, and returns the segmented output.\n",
        "    \n",
        "    Args:\n",
        "    image (numpy.ndarray): The uploaded MRI image.\n",
        "    \n",
        "    Returns:\n",
        "    numpy.ndarray: The segmented output image.\n",
        "    \"\"\"\n",
        "    # Assuming image is in the format of (128, 128) as expected by your existing code.\n",
        "    \n",
        "    # Slice the image into 64x64 patches\n",
        "    patches = slice_image(image)\n",
        "    \n",
        "    # Prepare the patches for model prediction\n",
        "    patches_data = np.array(patches).reshape((len(patches), 64, 64, 1))\n",
        "    \n",
        "    # Use the model to predict the segmentation of each patch\n",
        "    predictions = model3.predict(patches_data)\n",
        "    \n",
        "    # Reshape predictions for stitching\n",
        "    predictions = predictions.reshape((len(predictions), 64, 64))\n",
        "    \n",
        "    # Stitch the patches back together to form the full segmented image\n",
        "    segmented_image = stitch_image(predictions, original_shape=image.shape)\n",
        "    \n",
        "    return segmented_image\n",
        "\n",
        "# Define the Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=predict_mri,  # The function to be used for prediction\n",
        "    inputs=gr.Image(image_mode=\"L\"),  # Expecting grayscale MRI scans\n",
        "    outputs=gr.Image(image_mode=\"L\"),  # The output is also a grayscale image\n",
        "    title=\"MRI Scan Segmentation\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EFXT7pMePtEs"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
