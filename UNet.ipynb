{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_folder_path = 'BONBID2023_Train/1ADC_ss'\n",
    "adc_files = [os.path.join(adc_folder_path, f) for f in os.listdir(adc_folder_path) if f.endswith('.mha')]\n",
    "adc_files = sorted(adc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zadc_folder_path = 'BONBID2023_Train/2Z_ADC'\n",
    "zadc_files = [os.path.join(zadc_folder_path, f) for f in os.listdir(zadc_folder_path) if f.endswith('.mha')]\n",
    "zadc_files = sorted(zadc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder_path = 'BONBID2023_Train/3LABEL'\n",
    "label_files = [os.path.join(label_folder_path, f) for f in os.listdir(label_folder_path) if f.endswith('.mha')]\n",
    "label_files = sorted(label_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read and display data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display ADC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_data = []\n",
    "adc_stik_data = []\n",
    "for file in adc_files:\n",
    "    image = sitk.ReadImage(file)\n",
    "    adc_stik_data.append(image)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    adc_data.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(8,8))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    if i < adc_data[0].shape[0]:\n",
    "        ax.imshow(adc_data[0][i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display Zadc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zadc_data = []\n",
    "for file in zadc_files:\n",
    "    image = sitk.ReadImage(file)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    zadc_data.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(8,8))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    if i < zadc_data[0].shape[0]:\n",
    "        ax.imshow(zadc_data[0][i], cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = []\n",
    "for file in label_files:\n",
    "    image = sitk.ReadImage(file)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    label_data.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(8,8))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    if i < label_data[0].shape[0]:\n",
    "        ax.imshow(label_data[0][i], cmap=\"copper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ready data for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten a list of data with n length and (m, 128, 128) shape of each array, so it becomes a list of n*m of arrays of shape (128, 128)\n",
    "\n",
    "flattened_adc_data = [item for sublist in adc_data for item in sublist]\n",
    "flattened_zadc_data = [item for sublist in zadc_data for item in sublist]\n",
    "flattened_label_data = [item for sublist in label_data for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "flattened_zadc_data_train, flattened_zadc_data_test, flattened_label_data_train, flattened_label_data_test = train_test_split(flattened_zadc_data, flattened_label_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(image):\n",
    "    \"\"\"\n",
    "    Slices the given image into 64x64 patches.\n",
    "    \n",
    "    Args:\n",
    "    image (numpy.ndarray): The image to be sliced, expected shape is (H, W).\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of 64x64 image patches.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    h, w = image.shape\n",
    "    \n",
    "    if (h, w) == (256, 256):\n",
    "        # Slicing 256x256 image into sixteen non-overlapping 64x64 patches\n",
    "        for i in range(0, h, 64):\n",
    "            for j in range(0, w, 64):\n",
    "                patches.append(image[i:i+64, j:j+64])\n",
    "    elif (h, w) == (160, 160):\n",
    "        # Slicing 160x160 image with overlap to create 64x64 patches\n",
    "        for i in range(0, h-64+1, 64):\n",
    "            for j in range(0, w-64+1, 64):\n",
    "                patches.append(image[i:i+64, j:j+64])\n",
    "        # Adding overlapping patches\n",
    "        patches.append(image[96:160, 96:160])\n",
    "    elif (h, w) == (128, 128):\n",
    "        # Slicing 128x128 image with overlap to create 64x64 patches\n",
    "        for i in range(0, h-64+1, 64):\n",
    "            for j in range(0, w-64+1, 64):\n",
    "                patches.append(image[i:i+64, j:j+64])\n",
    "    elif (h, w) == (64, 64):\n",
    "        # Returning the image itself if it's already 64x64\n",
    "        patches.append(image)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image size. Expected (64, 64), (128, 128), (160, 160), or (256, 256).\")\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def process_images_and_labels(images, labels):\n",
    "    \"\"\"\n",
    "    Processes lists of images and labels, slicing each into 64x64 patches.\n",
    "    \n",
    "    Args:\n",
    "    images (list): List of numpy.ndarray images.\n",
    "    labels (list): List of numpy.ndarray labels corresponding to the images.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Two lists containing the sliced images and corresponding labels.\n",
    "    \"\"\"\n",
    "    all_image_patches = []\n",
    "    all_label_patches = []\n",
    "    \n",
    "    for image, label in zip(images, labels):\n",
    "        image_patches = slice_image(image)\n",
    "        label_patches = slice_image(label)\n",
    "        \n",
    "        all_image_patches.extend(image_patches)\n",
    "        all_label_patches.extend(label_patches)\n",
    "    \n",
    "    return all_image_patches, all_label_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_cropped_zadc_data_list, flattened_cropped_label_data_list = process_images_and_labels(flattened_zadc_data_train, flattened_label_data_train)\n",
    "\n",
    "flattened_test_cropped_zadc_data_list, flattened_test_cropped_label_data_list = process_images_and_labels(flattened_zadc_data_test, flattened_label_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_patches(original_image, patches):\n",
    "    \"\"\"\n",
    "    Display the 64x64 patches in a grid to verify their placement.\n",
    "    \n",
    "    Args:\n",
    "    original_image (numpy.ndarray): The original image before slicing.\n",
    "    patches (list): A list of 64x64 image patches.\n",
    "    \"\"\"\n",
    "    h, w = original_image.shape\n",
    "    fig, axs = plt.subplots(h // 64, w // 64, figsize=(10, 10))\n",
    "    \n",
    "    patch_index = 0\n",
    "    for i in range(h // 64):\n",
    "        for j in range(w // 64):\n",
    "            axs[i, j].imshow(patches[patch_index])\n",
    "            axs[i, j].axis('off')\n",
    "            patch_index += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display patches for the first image\n",
    "original_image = flattened_zadc_data_train[3]\n",
    "patches = slice_image(original_image)\n",
    "display_patches(original_image, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_image(patches, original_shape):\n",
    "    \"\"\"\n",
    "    Stitches 64x64 patches back together into the original image.\n",
    "    \n",
    "    Args:\n",
    "    patches (list): A list of 64x64 image patches.\n",
    "    original_shape (tuple): The shape of the original image (height, width).\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The reconstructed image.\n",
    "    \"\"\"\n",
    "    h, w = original_shape\n",
    "    reconstructed_image = np.zeros(original_shape)\n",
    "    \n",
    "    patch_index = 0\n",
    "    for i in range(0, h, 64):\n",
    "        for j in range(0, w, 64):\n",
    "            reconstructed_image[i:i+64, j:j+64] = patches[patch_index]\n",
    "            patch_index += 1\n",
    "    \n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display patches for the first image\n",
    "original_image = flattened_zadc_data_test[3]\n",
    "patches = slice_image(original_image)\n",
    "display_patches(original_image, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "flattened_cropped_zadc_data = np.array(flattened_cropped_zadc_data_list)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "flattened_cropped_zadc_data = flattened_cropped_zadc_data.reshape((len(flattened_cropped_zadc_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_cropped_zadc_data.shape)\n",
    "\n",
    "flattened_cropped_label_data = np.array(flattened_cropped_label_data_list)\n",
    "flattened_cropped_label_data = flattened_cropped_label_data.reshape((len(flattened_cropped_label_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_cropped_label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "flattened_test_cropped_zadc_data = np.array(flattened_test_cropped_zadc_data_list)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "flattened_test_cropped_zadc_data = flattened_test_cropped_zadc_data.reshape((len(flattened_test_cropped_zadc_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_test_cropped_zadc_data.shape)\n",
    "\n",
    "flattened_test_cropped_label_data = np.array(flattened_test_cropped_label_data_list)\n",
    "flattened_test_cropped_label_data = flattened_test_cropped_label_data.reshape((len(flattened_test_cropped_label_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_test_cropped_label_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **U Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def unet_model(input_size=(64, 64, 1), num_classes=1):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "\n",
    "    # Decoder\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid' if num_classes == 1 else 'softmax')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1e-05\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    \n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    gamma=2.0\n",
    "    alpha=0.25\n",
    "    \n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "    \n",
    "    # Cross-entropy loss for each class\n",
    "    cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "    \n",
    "    # Compute weight\n",
    "    weight = alpha * tf.math.pow((1 - y_pred), gamma)\n",
    "    \n",
    "    # Apply the focal loss\n",
    "    loss = weight * cross_entropy\n",
    "    loss = tf.reduce_sum(loss, axis=-1)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(y_true, y_pred):\n",
    "    loss = dice_loss(y_true, y_pred) + focal_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import saving\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "def total_loss_7525(y_true, y_pred):\n",
    "    loss = 0.75*dice_loss(y_true, y_pred) + 0.25*focal_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "    \n",
    "    p = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    r = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "    \n",
    "    f1 = 2 * p * r / (p + r + tf.keras.backend.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return tf.reduce_mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model 1: Dice Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "checkpoint_dir = '/Epochs/UNet64dice'\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, 'model_checkpoint_{epoch:02d}.keras')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "latest_checkpoint = max([os.path.join(checkpoint_dir, f) for f in os.listdir(checkpoint_dir) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
    "log_filepath = 'training_log_UNet64dice.csv'\n",
    "\n",
    "# Create the CSVLogger\n",
    "csv_logger = CSVLogger(log_filepath, append=True)\n",
    "\n",
    "# ModelCheckpoint callback to save the model\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1 = unet_model()\n",
    "model1.compile(optimizer='adam', loss=dice_loss, metrics=[MeanIoU(num_classes=2), f1_score])\n",
    "\n",
    "# Summary of the model\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    flattened_cropped_zadc_data, \n",
    "    flattened_cropped_label_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with validation data\n",
    "history = model1.fit(\n",
    "    X_train, y_train, epochs=500, batch_size=32, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[model_checkpoint_callback, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy, loss, and MeanIoU values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history1.history['mean_io_u'])\n",
    "plt.plot(history1.history['val_mean_io_u'])\n",
    "plt.title('Model MeanIoU')\n",
    "plt.ylabel('MeanIoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history1.history['f1_score'])\n",
    "plt.plot(history1.history['val_f1_score'])\n",
    "plt.title('Model F1 score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Add a main title to the entire figure\n",
    "plt.suptitle('Model 1 : UNet Dice Loss', fontsize=16)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('unetDice.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "IMAGE_NUMBER = 230\n",
    "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
    "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
    "patches = slice_image(original_image)\n",
    "\n",
    "patches_data = np.array(patches)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
    "\n",
    "predictions = model1.predict(patches_data)\n",
    "predictions = predictions.reshape((len(predictions), 64, 64))\n",
    "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('ZADC image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_image, cmap=\"grey\")\n",
    "plt.title('Label image')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
    "plt.title('Predicted image')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('unetDicePrediction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    'Adam',\n",
    "    loss=dice_loss,\n",
    "    metrics=[MeanIoU(num_classes=2), f1_score],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model1.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice):\")\n",
    "print(f\"Dice Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    'Adam',\n",
    "    loss=focal_loss,\n",
    "    metrics=[MeanIoU(num_classes=2), f1_score],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model1.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice):\")\n",
    "print(f\"Focal Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model 2: Dice+Focal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define paths\n",
    "checkpoint_dir2 = '/Epochs/UNet64dicefocal'\n",
    "checkpoint_filepath2 = os.path.join(checkpoint_dir2, 'model_checkpoint_{epoch:02d}.keras')\n",
    "if not os.path.exists(checkpoint_dir2):\n",
    "    os.makedirs(checkpoint_dir2)\n",
    "latest_checkpoint2 = max([os.path.join(checkpoint_dir2, f) for f in os.listdir(checkpoint_dir2) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
    "log_filepath2 = 'training_log_UNet64dicefocal.csv'\n",
    "\n",
    "# Create the CSVLogger\n",
    "csv_logger2 = CSVLogger(log_filepath2, append=True)\n",
    "\n",
    "# ModelCheckpoint callback to save the model\n",
    "model_checkpoint_callback2 = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath2,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model2 = unet_model()\n",
    "model2.compile(optimizer='adam', loss=total_loss, metrics=[MeanIoU(num_classes=2), f1_score])\n",
    "\n",
    "# Summary of the model\n",
    "# model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with validation data\n",
    "history2 = model2.fit(X_train2, y_train2, epochs=500, batch_size=32, validation_data=(X_val2, y_val2), callbacks=[model_checkpoint_callback2, csv_logger2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy, loss, and MeanIoU values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history2.history['mean_io_u'])\n",
    "plt.plot(history2.history['val_mean_io_u'])\n",
    "plt.title('Model MeanIoU')\n",
    "plt.ylabel('MeanIoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history2.history['f1_score'])\n",
    "plt.plot(history2.history['val_f1_score'])\n",
    "plt.title('Model F1 score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Add a main title to the entire figure\n",
    "plt.suptitle('Model 2 : UNet Dice+Focal Loss', fontsize=16)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('unetDiceFocal.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "IMAGE_NUMBER = 230\n",
    "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
    "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
    "patches = slice_image(original_image)\n",
    "\n",
    "patches_data = np.array(patches)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
    "\n",
    "predictions = model2.predict(patches_data)\n",
    "predictions = predictions.reshape((len(predictions), 64, 64))\n",
    "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('ZADC image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_image, cmap=\"grey\")\n",
    "plt.title('Label image')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
    "plt.title('Predicted image')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('unetDiceFocalPrediction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    'Adam',\n",
    "    loss=dice_loss,\n",
    "    metrics=[MeanIoU(num_classes=2), f1_score],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model2.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice+Focal):\")\n",
    "print(f\"Dice Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    'Adam',\n",
    "    loss=focal_loss,\n",
    "    metrics=[MeanIoU(num_classes=2), f1_score],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model2.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data(Dice+Focal):\")\n",
    "print(f\"Focal Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model 3: 0.75 Dice + 0.25 Focal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define paths\n",
    "checkpoint_dir3 = '/Epochs/UNet75dice25focal'\n",
    "checkpoint_filepath3 = os.path.join(checkpoint_dir3, 'model_checkpoint_{epoch:02d}.keras')\n",
    "if not os.path.exists(checkpoint_dir3):\n",
    "    os.makedirs(checkpoint_dir3)\n",
    "latest_checkpoint3 = max([os.path.join(checkpoint_dir3, f) for f in os.listdir(checkpoint_dir3) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
    "log_filepath3 = 'training_log_UNet75dice25focal.csv'\n",
    "\n",
    "# Create the CSVLogger\n",
    "csv_logger3 = CSVLogger(log_filepath3, append=True)\n",
    "\n",
    "# ModelCheckpoint callback to save the model\n",
    "model_checkpoint_callback3 = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath3,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model3 = unet_model()\n",
    "model3.compile(optimizer='adam', loss=total_loss_7525, metrics=[MeanIoU(num_classes=2), f1_score])\n",
    "\n",
    "# Summary of the model\n",
    "# model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model with validation data\n",
    "history3 = model3.fit(X_train3, y_train3, epochs=500, batch_size=32, validation_data=(X_val3, y_val3), callbacks=[model_checkpoint_callback3, csv_logger3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy, loss, and MeanIoU values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history3.history['mean_io_u'])\n",
    "plt.plot(history3.history['val_mean_io_u'])\n",
    "plt.title('Model MeanIoU')\n",
    "plt.ylabel('MeanIoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history3.history['f1_score'])\n",
    "plt.plot(history3.history['val_f1_score'])\n",
    "plt.title('Model F1 score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Add a main title to the entire figure\n",
    "plt.suptitle('Model 3 : UNet 0.75 Dice + 0.25 Focal Loss', fontsize=16)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('unet75Dice25Focal.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "IMAGE_NUMBER = 230\n",
    "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
    "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
    "patches = slice_image(original_image)\n",
    "\n",
    "patches_data = np.array(patches)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
    "\n",
    "predictions = model3.predict(patches_data)\n",
    "predictions = predictions.reshape((len(predictions), 64, 64))\n",
    "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('ZADC image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_image, cmap=\"grey\")\n",
    "plt.title('Label image')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
    "plt.title('Predicted image')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('unet75Dice25FocalPrediction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    'Adam',\n",
    "    loss=dice_loss,\n",
    "    metrics=[MeanIoU(num_classes=2), f1_score],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model3.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (0.75 Dice + 0.25 Focal):\")\n",
    "print(f\"Dice Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    'Adam',\n",
    "    loss=focal_loss,\n",
    "    metrics=[MeanIoU(num_classes=2), f1_score],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model3.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (0.75 Dice + 0.25 Focal):\")\n",
    "print(f\"Focal Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
