{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_folder_path = 'BONBID2023_Train/1ADC_ss'\n",
    "adc_files = [os.path.join(adc_folder_path, f) for f in os.listdir(adc_folder_path) if f.endswith('.mha')]\n",
    "adc_files = sorted(adc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zadc_folder_path = 'BONBID2023_Train/2Z_ADC'\n",
    "zadc_files = [os.path.join(zadc_folder_path, f) for f in os.listdir(zadc_folder_path) if f.endswith('.mha')]\n",
    "zadc_files = sorted(zadc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder_path = 'BONBID2023_Train/3LABEL'\n",
    "label_files = [os.path.join(label_folder_path, f) for f in os.listdir(label_folder_path) if f.endswith('.mha')]\n",
    "label_files = sorted(label_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Read and display data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display ADC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_data = []\n",
    "adc_stik_data = []\n",
    "for file in adc_files:\n",
    "    image = sitk.ReadImage(file)\n",
    "    adc_stik_data.append(image)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    adc_data.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(8,8))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    if i < adc_data[0].shape[0]:\n",
    "        ax.imshow(adc_data[0][i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display Zadc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zadc_data = []\n",
    "for file in zadc_files:\n",
    "    image = sitk.ReadImage(file)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    zadc_data.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(8,8))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    if i < zadc_data[0].shape[0]:\n",
    "        ax.imshow(zadc_data[0][i], cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = []\n",
    "for file in label_files:\n",
    "    image = sitk.ReadImage(file)\n",
    "    array = sitk.GetArrayFromImage(image)\n",
    "    label_data.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(8,8))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    if i < label_data[0].shape[0]:\n",
    "        ax.imshow(label_data[0][i], cmap=\"copper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ready data for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten a list of data with n length and (m, 128, 128) shape of each array, so it becomes a list of n*m of arrays of shape (128, 128)\n",
    "\n",
    "flattened_adc_data = [item for sublist in adc_data for item in sublist]\n",
    "flattened_zadc_data = [item for sublist in zadc_data for item in sublist]\n",
    "flattened_label_data = [item for sublist in label_data for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "flattened_zadc_data_train, flattened_zadc_data_test, flattened_label_data_train, flattened_label_data_test = train_test_split(flattened_zadc_data, flattened_label_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_image(image):\n",
    "    \"\"\"\n",
    "    Slices the given image into 64x64 patches.\n",
    "    \n",
    "    Args:\n",
    "    image (numpy.ndarray): The image to be sliced, expected shape is (H, W).\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of 64x64 image patches.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    h, w = image.shape\n",
    "    \n",
    "    if (h, w) == (256, 256):\n",
    "        # Slicing 256x256 image into sixteen non-overlapping 64x64 patches\n",
    "        for i in range(0, h, 64):\n",
    "            for j in range(0, w, 64):\n",
    "                patches.append(image[i:i+64, j:j+64])\n",
    "    elif (h, w) == (160, 160):\n",
    "        # Slicing 160x160 image with overlap to create 64x64 patches\n",
    "        for i in range(0, h-64+1, 64):\n",
    "            for j in range(0, w-64+1, 64):\n",
    "                patches.append(image[i:i+64, j:j+64])\n",
    "        # Adding overlapping patches\n",
    "        patches.append(image[96:160, 96:160])\n",
    "    elif (h, w) == (128, 128):\n",
    "        # Slicing 128x128 image with overlap to create 64x64 patches\n",
    "        for i in range(0, h-64+1, 64):\n",
    "            for j in range(0, w-64+1, 64):\n",
    "                patches.append(image[i:i+64, j:j+64])\n",
    "    elif (h, w) == (64, 64):\n",
    "        # Returning the image itself if it's already 64x64\n",
    "        patches.append(image)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image size. Expected (64, 64), (128, 128), (160, 160), or (256, 256).\")\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def process_images_and_labels(images, labels):\n",
    "    \"\"\"\n",
    "    Processes lists of images and labels, slicing each into 64x64 patches.\n",
    "    \n",
    "    Args:\n",
    "    images (list): List of numpy.ndarray images.\n",
    "    labels (list): List of numpy.ndarray labels corresponding to the images.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Two lists containing the sliced images and corresponding labels.\n",
    "    \"\"\"\n",
    "    all_image_patches = []\n",
    "    all_label_patches = []\n",
    "    \n",
    "    for image, label in zip(images, labels):\n",
    "        image_patches = slice_image(image)\n",
    "        label_patches = slice_image(label)\n",
    "        \n",
    "        all_image_patches.extend(image_patches)\n",
    "        all_label_patches.extend(label_patches)\n",
    "    \n",
    "    return all_image_patches, all_label_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_cropped_zadc_data_list, flattened_cropped_label_data_list = process_images_and_labels(flattened_zadc_data_train, flattened_label_data_train)\n",
    "\n",
    "flattened_test_cropped_zadc_data_list, flattened_test_cropped_label_data_list = process_images_and_labels(flattened_zadc_data_test, flattened_label_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_patches(original_image, patches):\n",
    "    \"\"\"\n",
    "    Display the 64x64 patches in a grid to verify their placement.\n",
    "    \n",
    "    Args:\n",
    "    original_image (numpy.ndarray): The original image before slicing.\n",
    "    patches (list): A list of 64x64 image patches.\n",
    "    \"\"\"\n",
    "    h, w = original_image.shape\n",
    "    fig, axs = plt.subplots(h // 64, w // 64, figsize=(10, 10))\n",
    "    \n",
    "    patch_index = 0\n",
    "    for i in range(h // 64):\n",
    "        for j in range(w // 64):\n",
    "            axs[i, j].imshow(patches[patch_index])\n",
    "            axs[i, j].axis('off')\n",
    "            patch_index += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display patches for the first image\n",
    "original_image = flattened_zadc_data_train[3]\n",
    "patches = slice_image(original_image)\n",
    "display_patches(original_image, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_image(patches, original_shape):\n",
    "    \"\"\"\n",
    "    Stitches 64x64 patches back together into the original image.\n",
    "    \n",
    "    Args:\n",
    "    patches (list): A list of 64x64 image patches.\n",
    "    original_shape (tuple): The shape of the original image (height, width).\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The reconstructed image.\n",
    "    \"\"\"\n",
    "    h, w = original_shape\n",
    "    reconstructed_image = np.zeros(original_shape)\n",
    "    \n",
    "    patch_index = 0\n",
    "    for i in range(0, h, 64):\n",
    "        for j in range(0, w, 64):\n",
    "            reconstructed_image[i:i+64, j:j+64] = patches[patch_index]\n",
    "            patch_index += 1\n",
    "    \n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display patches for the first image\n",
    "original_image = flattened_zadc_data_test[3]\n",
    "patches = slice_image(original_image)\n",
    "display_patches(original_image, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "flattened_cropped_zadc_data = np.array(flattened_cropped_zadc_data_list)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "flattened_cropped_zadc_data = flattened_cropped_zadc_data.reshape((len(flattened_cropped_zadc_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_cropped_zadc_data.shape)\n",
    "\n",
    "flattened_cropped_label_data = np.array(flattened_cropped_label_data_list)\n",
    "flattened_cropped_label_data = flattened_cropped_label_data.reshape((len(flattened_cropped_label_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_cropped_label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "# Convert the list of arrays to a single NumPy array\n",
    "flattened_test_cropped_zadc_data = np.array(flattened_test_cropped_zadc_data_list)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "flattened_test_cropped_zadc_data = flattened_test_cropped_zadc_data.reshape((len(flattened_test_cropped_zadc_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_test_cropped_zadc_data.shape)\n",
    "\n",
    "flattened_test_cropped_label_data = np.array(flattened_test_cropped_label_data_list)\n",
    "flattened_test_cropped_label_data = flattened_test_cropped_label_data.reshape((len(flattened_test_cropped_label_data_list), 64, 64, 1))\n",
    "\n",
    "# Print the shape to verify\n",
    "print(flattened_test_cropped_label_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **U Net: VGG19**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm\n",
    "# Segmentation Models: using `keras` framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model 1: Dice Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "checkpoint_dir = '/Epochs/VGG19dice'\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, 'model_checkpoint_{epoch:02d}.keras')\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "latest_checkpoint = max([os.path.join(checkpoint_dir, f) for f in os.listdir(checkpoint_dir) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
    "log_filepath = 'training_log_VGG19dice.csv'\n",
    "\n",
    "# Create the CSVLogger\n",
    "csv_logger = CSVLogger(log_filepath, append=True)\n",
    "\n",
    "# ModelCheckpoint callback to save the model\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BACKBONE = 'vgg19'\n",
    "\n",
    "# load your data\n",
    "x_train1, x_val1, y_train1, y_val1 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# define model\n",
    "model1 = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(64, 64, 1))\n",
    "model1.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.DiceLoss,\n",
    "    metrics=[sm.metrics.iou_score, sm.metrics.FScore],\n",
    ")\n",
    "\n",
    "history1 = model1.fit(\n",
    "   x=x_train1,\n",
    "   y=y_train1,\n",
    "   batch_size=32,\n",
    "   epochs=500,\n",
    "   validation_data=(x_val1, y_val1),\n",
    "   callbacks=[model_checkpoint_callback, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy, loss, and MeanIoU values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history1.history['iou_score'])\n",
    "plt.plot(history1.history['val_iou_score'])\n",
    "plt.title('Model MeanIoU')\n",
    "plt.ylabel('MeanIoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history1.history['f1-score'])\n",
    "plt.plot(history1.history['val_f1-score'])\n",
    "plt.title('Model F1 Score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Add a main title to the entire figure\n",
    "plt.suptitle('Model 1 : VGG19 Dice Loss', fontsize=16)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('vggDice.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "IMAGE_NUMBER = 230\n",
    "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
    "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
    "patches = slice_image(original_image)\n",
    "\n",
    "patches_data = np.array(patches)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
    "\n",
    "predictions = model1.predict(patches_data)\n",
    "predictions = predictions.reshape((len(predictions), 64, 64))\n",
    "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('ZADC image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_image, cmap=\"grey\")\n",
    "plt.title('Label image')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
    "plt.title('Predicted image')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('vggDicePrediction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    'Adam',\n",
    "    loss=dice_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model1.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice):\")\n",
    "print(f\"Dice Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    'Adam',\n",
    "    loss=focal_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model1.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice):\")\n",
    "print(f\"Focal Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model 2: Dice + Focal Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "checkpoint_dir2 = '/Epochs/VGG19dicefocal'\n",
    "checkpoint_filepath2 = os.path.join(checkpoint_dir2, 'model_checkpoint_{epoch:02d}.keras')\n",
    "if not os.path.exists(checkpoint_dir2):\n",
    "    os.makedirs(checkpoint_dir2)\n",
    "latest_checkpoint2 = max([os.path.join(checkpoint_dir2, f) for f in os.listdir(checkpoint_dir2) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
    "log_filepath2 = 'training_log_VGG19dicefocal.csv'\n",
    "        \n",
    "# Create the CSVLogger\n",
    "csv_logger2 = CSVLogger(log_filepath2, append=True)\n",
    "\n",
    "# ModelCheckpoint callback to save the model\n",
    "model_checkpoint_callback2 = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath2,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BACKBONE = 'vgg19'\n",
    "\n",
    "# load your data\n",
    "x_train2, x_val2, y_train2, y_val2 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# define model\n",
    "model2 = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(64, 64, 1))\n",
    "\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
    "\n",
    "model2.compile(\n",
    "    'Adam',\n",
    "    loss=total_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "history2 = model2.fit(\n",
    "   x=x_train2,\n",
    "   y=y_train2,\n",
    "   batch_size=32,\n",
    "   epochs=500,\n",
    "   validation_data=(x_val2, y_val2),\n",
    "   callbacks=[model_checkpoint_callback2, csv_logger2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy, loss, and MeanIoU values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history2.history['iou_score'])\n",
    "plt.plot(history2.history['val_iou_score'])\n",
    "plt.title('Model MeanIoU')\n",
    "plt.ylabel('MeanIoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history2.history['f1-score'])\n",
    "plt.plot(history2.history['val_f1-score'])\n",
    "plt.title('Model F1 Score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Add a main title to the entire figure\n",
    "plt.suptitle('Model 2 : VGG19 Dice + Focal Loss', fontsize=16)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('vggDiceFocal.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "IMAGE_NUMBER = 230\n",
    "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
    "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
    "patches = slice_image(original_image)\n",
    "\n",
    "patches_data = np.array(patches)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
    "\n",
    "predictions = model2.predict(patches_data)\n",
    "predictions = predictions.reshape((len(predictions), 64, 64))\n",
    "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('ZADC image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_image, cmap=\"grey\")\n",
    "plt.title('Label image')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
    "plt.title('Predicted image')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('vggDiceFocalPrediction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    'Adam',\n",
    "    loss=dice_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model2.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice+Focal):\")\n",
    "print(f\"Dice Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    'Adam',\n",
    "    loss=focal_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model2.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (Dice+Focal):\")\n",
    "print(f\"Focal Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model 3: 0.75 Dice + 0.25 Focal Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "checkpoint_dir3 = '/Epochs/VGG1975dice25focal'\n",
    "checkpoint_filepath3 = os.path.join(checkpoint_dir3, 'model_checkpoint_{epoch:02d}.keras')\n",
    "if not os.path.exists(checkpoint_dir3):\n",
    "    os.makedirs(checkpoint_dir3)\n",
    "latest_checkpoint3 = max([os.path.join(checkpoint_dir3, f) for f in os.listdir(checkpoint_dir3) if f.startswith('model_checkpoint')], key=os.path.getctime, default=None)\n",
    "log_filepath3 = 'training_log_VGG1975dice25focal.csv'\n",
    "\n",
    "# Create the CSVLogger\n",
    "csv_logger3 = CSVLogger(log_filepath3, append=True)\n",
    "\n",
    "# ModelCheckpoint callback to save the model\n",
    "model_checkpoint_callback3 = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath3,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_io_u',\n",
    "    mode='max',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BACKBONE = 'vgg19'\n",
    "\n",
    "# load your data\n",
    "x_train3, x_val3, y_train3, y_val3 = train_test_split(flattened_cropped_zadc_data, flattened_cropped_label_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# define model\n",
    "model3 = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(64, 64, 1))\n",
    "\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "total_loss = (0.75 * dice_loss) + (0.25 * focal_loss)\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
    "\n",
    "model3.compile(\n",
    "    'Adam',\n",
    "    loss=total_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "history3 = model3.fit(\n",
    "   x=x_train3,\n",
    "   y=y_train3,\n",
    "   batch_size=32,\n",
    "   epochs=500,\n",
    "   validation_data=(x_val3, y_val3),\n",
    "   callbacks=[model_checkpoint_callback3, csv_logger3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy, loss, and MeanIoU values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history3.history['iou_score'])\n",
    "plt.plot(history3.history['val_iou_score'])\n",
    "plt.title('Model MeanIoU')\n",
    "plt.ylabel('MeanIoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history3.history['f1-score'])\n",
    "plt.plot(history3.history['val_f1-score'])\n",
    "plt.title('Model F1 Score')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Add a main title to the entire figure\n",
    "plt.suptitle('Model 3 : VGG19 0.75 Dice + 0.25 Focal Loss', fontsize=16)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust `rect` to make space for the suptitle\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('vgg75Dice25Focal.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "IMAGE_NUMBER = 230\n",
    "original_image = flattened_zadc_data_test[IMAGE_NUMBER]\n",
    "label_image = flattened_label_data_test[IMAGE_NUMBER]\n",
    "patches = slice_image(original_image)\n",
    "\n",
    "patches_data = np.array(patches)\n",
    "\n",
    "# Reshape the array to have shape (num_samples, 128, 128, 1)\n",
    "patches_data = patches_data.reshape((len(patches), 64, 64, 1))\n",
    "\n",
    "predictions = model3.predict(patches_data)\n",
    "predictions = predictions.reshape((len(predictions), 64, 64))\n",
    "reconstructed_image = stitch_image(predictions, original_image.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_image)\n",
    "plt.title('ZADC image')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_image, cmap=\"grey\")\n",
    "plt.title('Label image')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(reconstructed_image, cmap=\"grey\")\n",
    "plt.title('Predicted image')\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('vgg75Dice25FocalPrediction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    'Adam',\n",
    "    loss=dice_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model3.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (0.75 Dice + 0.25 Focal):\")\n",
    "print(f\"Dice Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    'Adam',\n",
    "    loss=focal_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model3.evaluate(flattened_test_cropped_zadc_data, flattened_test_cropped_label_data, batch_size=32)\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results on test data (0.75 Dice + 0.25 Focal):\")\n",
    "print(f\"Focal Loss: {evaluation[0]}\")\n",
    "print(f\"IOU Score: {evaluation[1]}\")\n",
    "print(f\"F1 Score: {evaluation[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
